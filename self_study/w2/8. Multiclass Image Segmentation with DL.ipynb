{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multiclass Image Segmentation with DL\n",
    "\n",
    "Outline\n",
    "\n",
    "1. The Dataset\n",
    "2. Loading all to memory\n",
    "3. Flow from directory\n",
    "\n",
    "In the previous notebook, you trained a U-Net for a single class. But what if there are multiple classes? One approach is to train a binary model for each class. This allows individual optimization for each class, which can be advantageous. Alternatively, you could train a single multiclass model, enabling it to learn inter-class relationships.\n",
    "\n",
    "Both approaches have their pros and cons, so the best strategy is to try both and compare their performance to decide which works best for your use case.\n",
    "\n",
    "In this notebook, I will adjust the network from the previous notebook to make it multi-class. We also need a dataset, as blood cell dataset is binary. I simulated a simple multi-class dataset for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the code, I wanted to create a very simple dataset. Each image contains a triangle and a rectangle. Masks are single channel labeled images where 0 is the background, 1 is the rectangle and 2 is the triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlap(rect1, rect2):\n",
    "    if (rect1[0] < rect2[0] + rect2[2]) and (rect1[0] + rect1[2] > rect2[0]) and \\\n",
    "       (rect1[1] < rect2[1] + rect2[3]) and (rect1[1] + rect1[3] > rect2[1]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def generate_non_overlapping_rect(existing_rects, max_attempts=100):\n",
    "    for _ in range(max_attempts):\n",
    "        x, y = np.random.randint(20, 44, size=2)\n",
    "        size = np.random.randint(10, 20)\n",
    "        new_rect = (x, y, size, size)\n",
    "        if not any(is_overlap(new_rect, rect) for rect in existing_rects):\n",
    "            return new_rect\n",
    "    return None\n",
    "\n",
    "def generate_dataset(num_images, output_dir, dataset_type):\n",
    "    for subdir in [f'{dataset_type}_images/{dataset_type}', f'{dataset_type}_masks/{dataset_type}']:\n",
    "        os.makedirs(os.path.join(output_dir, subdir), exist_ok=True)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        image = np.zeros((64, 64, 3), dtype=np.uint8)\n",
    "        mask = np.zeros((64, 64), dtype=np.uint8)\n",
    "        existing_rects = []\n",
    "\n",
    "        # Generate a rectangle\n",
    "        rect = generate_non_overlapping_rect(existing_rects)\n",
    "        if rect is not None:\n",
    "            x, y, size, _ = rect\n",
    "            existing_rects.append(rect)\n",
    "            image = cv2.rectangle(image, (x, y), (x + size, y + size), (255, 255, 255), -1)\n",
    "            mask = cv2.rectangle(mask, (x, y), (x + size, y + size), 1, -1)\n",
    "\n",
    "        # Generate a triangle\n",
    "        rect = generate_non_overlapping_rect(existing_rects)\n",
    "        if rect is not None:\n",
    "            x, y, size, _ = rect\n",
    "            points = np.array([[x, y], [x + size, y], [x, y + size]], np.int32)\n",
    "            image = cv2.fillConvexPoly(image, points, (255, 255, 255))\n",
    "            mask = cv2.fillConvexPoly(mask, points, 2)\n",
    "\n",
    "        cv2.imwrite(f'{output_dir}/{dataset_type}_images/{dataset_type}/{i}.png', image)\n",
    "        cv2.imwrite(f'{output_dir}/{dataset_type}_masks/{dataset_type}/{i}.png', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you run this block\n",
    "# it will create a folder where the notebook is\n",
    "# and populate it with the dataset\n",
    "output_dir = 'shapes_dataset'\n",
    "\n",
    "generate_dataset(500, output_dir, 'train')\n",
    "generate_dataset(100, output_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1743c39a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEQCAYAAAAQ4xaZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbUUlEQVR4nO3df2xV9f3H8dfVC5eW3d4NlXu5obAab6auoki1Wojtpq3hSwzGxTlBp1mywADlShag8w87s92LLOPLTCcbZHGYjbE/xMEylXZxXHWNs2Iau7L4I3azU+46XXdvVXYL8vn+4bdnvbRob3vv5/56PpLPHz3n3Hvf/QBvXvdzzj3XZYwxAgAAsOScfBcAAADKC+EDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWJWz8PHII4+opqZGs2bN0pIlS/Tcc8/l6qUAlAj6BlAe3Ll40l//+tcKh8N65JFHtHTpUv30pz/V8uXLdezYMS1YsOATH3v69Gm988478nq9crlcuSgPwKcwxmh4eFjBYFDnnGNngXQ6fUOidwD5llHfMDlw9dVXm7Vr16Ztu/jii83WrVs/9bEDAwNGEoPBKIAxMDCQixYxoen0DWPoHQxGoYzJ9I2sr3yMjIzo6NGj2rp1a9r2lpYWdXV1jTs+lUoplUo5Pxu+ZBcoGF6v18rrZNo3pLP3jmX6H7k1I3fFApjQKZ3U83pyUn0j6+Hj3Xff1UcffSS/35+23e/3Kx6Pjzs+Go3qu9/9brbLAJAFtk5fZNo3pLP3DrdmyO0ifADW/f/awWT6Rs5O5p754saYCQtqbW1VIpFwxsDAQK5KAlDgJts3JHoHUMyyvvJx/vnn69xzzx33bmVwcHDcuxpJ8ng88ng82S4DQBHJtG9I9A6gmGV95WPmzJlasmSJOjs707Z3dnaqoaEh2y8HoATQN4DykpOP2m7atEl33nmn6urqdO2112r37t166623tHbt2ly8HIASQN8AykdOwsdtt92m9957Tw8++KCOHz+u2tpaPfnkk1q4cGEuXg5ACaBvAOXDZQrss63JZFI+ny/fZQCQlEgkVFVVle8yJmW0dzRpJZ92AfLglDmpIzo4qb7Bd7sAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsyjh8PPvss7rpppsUDAblcrn0m9/8Jm2/MUZtbW0KBoOqqKhQU1OT+vr6slUvgCJE3wAwVsbh44MPPtDll1+u9vb2Cfdv375dO3bsUHt7u7q7uxUIBNTc3Kzh4eFpFwugONE3AIzlzvQBy5cv1/LlyyfcZ4zRzp07df/99+uWW26RJO3du1d+v1/79u3TmjVrplctgKJE3wAwVlav+ejv71c8HldLS4uzzePxqLGxUV1dXRM+JpVKKZlMpg0A5WMqfUOidwDFLKvhIx6PS5L8fn/adr/f7+w7UzQalc/nc0Z1dXU2SwJQ4KbSNyR6B1DMcvJpF5fLlfazMWbctlGtra1KJBLOGBgYyEVJAApcJn1DoncAxSzjaz4+SSAQkPTxO5l58+Y52wcHB8e9qxnl8Xjk8XiyWQaAIjKVviHRO4BiltWVj5qaGgUCAXV2djrbRkZGFIvF1NDQkM2XAlAi6BtA+cl45eP999/XG2+84fzc39+vnp4ezZkzRwsWLFA4HFYkElEoFFIoFFIkElFlZaVWrVqV1cIBFA/6BoCxMg4fL730kr70pS85P2/atEmSdNddd+nnP/+5Nm/erBMnTmjdunUaGhpSfX29Ojo65PV6s1c1gKJC3wAwlssYY/JdxFjJZFI+ny/fZQCQlEgkVFVVle8yJmW0dzRppdyuGfkuByg7p8xJHdHBSfUNvtsFAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgVUbhIxqN6qqrrpLX69XcuXN1880369VXX007xhijtrY2BYNBVVRUqKmpSX19fVktGkBxoXcAGCuj8BGLxbR+/Xq98MIL6uzs1KlTp9TS0qIPPvjAOWb79u3asWOH2tvb1d3drUAgoObmZg0PD2e9eADFgd4BYCyXMcZM9cH//Oc/NXfuXMViMV133XUyxigYDCocDmvLli2SpFQqJb/fr4ceekhr1qz51OdMJpPy+XxTLQlAFiUSCVVVVWX9eXPZO5q0Um7XjKzXDOCTnTIndUQHJ9U3pnXNRyKRkCTNmTNHktTf3694PK6WlhbnGI/Ho8bGRnV1dU34HKlUSslkMm0AKG30DqC8TTl8GGO0adMmLVu2TLW1tZKkeDwuSfL7/WnH+v1+Z9+ZotGofD6fM6qrq6daEoAiQO8AMOXwsWHDBr3yyiv61a9+NW6fy+VK+9kYM27bqNbWViUSCWcMDAxMtSQARYDeAcA9lQfdc889OnTokJ599lnNnz/f2R4IBCR9/C5m3rx5zvbBwcFx72hGeTweeTyeqZQBoMjQOwBIGa58GGO0YcMGHThwQM8884xqamrS9tfU1CgQCKizs9PZNjIyolgspoaGhuxUDKDo0DsAjJXRysf69eu1b98+HTx4UF6v1zkX6/P5VFFRIZfLpXA4rEgkolAopFAopEgkosrKSq1atSonvwCAwkfvADBWRuFj165dkqSmpqa07Y8++qjuvvtuSdLmzZt14sQJrVu3TkNDQ6qvr1dHR4e8Xm9WCgZQfOgdAMaa1n0+coH7fACFI1f3+cgF7vMB5Je1+3wAAABkivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAqoy+1RalocC+SzAnXC5XvksASs7hd3ryXULO3Ri8It8llAVWPgAAgFWEDwAAYBWnXVASOM0CYCo4zZIfrHwAAACrCB8AAMAqwgcAALCKaz5QtLjOA8BUcJ1H/rHyAQAArCJ8AAAAqzjtgqLBaRYAU8FplsLDygcAALCK8AEAAKzKKHzs2rVLixYtUlVVlaqqqnTttdfqqaeecvYbY9TW1qZgMKiKigo1NTWpr68v60UDKC70DgBjZRQ+5s+fr23btumll17SSy+9pC9/+ctauXKl0yS2b9+uHTt2qL29Xd3d3QoEAmpubtbw8HBOikfpc7lczkDxonfAthuDVzgDhcdlpvn96nPmzNEPfvADfeMb31AwGFQ4HNaWLVskSalUSn6/Xw899JDWrFkz4eNTqZRSqZTzczKZVHV19XRKwqeY5h+5VYSO/EokEqqqqsrJc+eqdzRppdyuGTmpudwdfqcn3yVMGqHDvlPmpI7o4KT6xpSv+fjoo4+0f/9+ffDBB7r22mvV39+veDyulpYW5xiPx6PGxkZ1dXWd9Xmi0ah8Pp8zCB5AaaN3AMg4fPT29uozn/mMPB6P1q5dqyeeeEKXXnqp4vG4JMnv96cd7/f7nX0TaW1tVSKRcMbAwECmJaGEjD3NwqpHaaF3IJfGnmZh1aPwZXyfjy984Qvq6enRv//9bz3++OO66667FIvFnP1n/odhjPnE/0Q8Ho88Hk+mZQAoMvQOAKMyXvmYOXOmLrroItXV1Skajeryyy/Xj370IwUCAUka905lcHBw3DsaAOWH3gFg1LTv82GMUSqVUk1NjQKBgDo7O519IyMjisViamhomO7LACgx9A6gfGV02uU73/mOli9frurqag0PD2v//v06cuSInn76ablcLoXDYUUiEYVCIYVCIUUiEVVWVmrVqlW5qh8lgGs7Sh+9A7nAtR3FK6Pw8Y9//EN33nmnjh8/Lp/Pp0WLFunpp59Wc3OzJGnz5s06ceKE1q1bp6GhIdXX16ujo0NerzcnxQMoDvQOAGNN+z4f2ZZMJuXz+fJdRkkrsD9yVj4KWC7v85Fto72D+3zkTqHd54OVj8Ji5T4fAAAAU5HxR22B6WKlA8BUsNJROlj5AAAAVhE+AACAVZx2gRWcagEwFZxqKU2sfAAAAKsIHwAAwCrCBwAAsIprPpATXOMBYCq4xqM8sPIBAACsInwAAACrOO2CrOA0C4Cp4DRLeWLlAwAAWEX4AAAAVhE+AACAVVzzgSnjOg8AU8F1HmDlAwAAWEX4AAAAVnHaBZPGaRYAU8FpFpyJlQ8AAGAV4QMAAFhF+AAAAFZxzQc+Edd5AJgKrvPAJ2HlAwAAWDWt8BGNRuVyuRQOh51txhi1tbUpGAyqoqJCTU1N6uvrm26dAEoEfQPAlMNHd3e3du/erUWLFqVt3759u3bs2KH29nZ1d3crEAioublZw8PD0y4WuedyudIGkE30jdJ1Y/CKtAF8kimFj/fff1+rV6/Wnj179LnPfc7ZbozRzp07df/99+uWW25RbW2t9u7dqw8//FD79u2b8LlSqZSSyWTaAFB6stk3JHoHUMymFD7Wr1+vFStW6IYbbkjb3t/fr3g8rpaWFmebx+NRY2Ojurq6JnyuaDQqn8/njOrq6qmUBKDAZbNvSPQOoJhlHD7279+vl19+WdFodNy+eDwuSfL7/Wnb/X6/s+9Mra2tSiQSzhgYGMi0JAAFLtt9Q6J3AMUso4/aDgwMaOPGjero6NCsWbPOetyZ1woYY856/YDH45HH48mkDGTZ2D8bY0weK8k/rnPJvlz0DYneUQjGXtvxxv9ek79CCsBF972Q7xKKSkYrH0ePHtXg4KCWLFkit9stt9utWCymhx9+WG6323nncua7lcHBwXHvagCUB/oGgDNlFD6uv/569fb2qqenxxl1dXVavXq1enp6dOGFFyoQCKizs9N5zMjIiGKxmBoaGrJePIDCR98AcKaMTrt4vV7V1tambZs9e7bOO+88Z3s4HFYkElEoFFIoFFIkElFlZaVWrVqVvaoxLZxagE30jdLBR2iRLVm/vfrmzZt14sQJrVu3TkNDQ6qvr1dHR4e8Xm+2XwpAiaBvAOXFZQrsCsNkMimfz5fvMspWgf11sI5VoXSJREJVVVX5LmNSRntHk1bK7ZqR73LKDheccsHpKXNSR3RwUn2D73YBAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYlVH4aGtrk8vlShuBQMDZb4xRW1ubgsGgKioq1NTUpL6+vqwXDaC40DsAjJXxyscXv/hFHT9+3Bm9vb3Ovu3bt2vHjh1qb29Xd3e3AoGAmpubNTw8nNWiARQfegeAURmHD7fbrUAg4IwLLrhA0sfvXHbu3Kn7779ft9xyi2pra7V37159+OGH2rdvX9YLB1Bc6B0ARmUcPl5//XUFg0HV1NToa1/7mt58801JUn9/v+LxuFpaWpxjPR6PGhsb1dXVddbnS6VSSiaTaQNA6aF3ABiVUfior6/XY489psOHD2vPnj2Kx+NqaGjQe++9p3g8Lkny+/1pj/H7/c6+iUSjUfl8PmdUV1dP4dcAUMjoHQDGyih8LF++XF/5yld02WWX6YYbbtDvfvc7SdLevXudY1wuV9pjjDHjto3V2tqqRCLhjIGBgUxKAlAE6B0AxprWR21nz56tyy67TK+//rpz5fqZ71QGBwfHvaMZy+PxqKqqKm0AKG30DqC8TSt8pFIp/eUvf9G8efNUU1OjQCCgzs5OZ//IyIhisZgaGhqmXSiA0kHvAMqbO5ODv/3tb+umm27SggULNDg4qO9973tKJpO666675HK5FA6HFYlEFAqFFAqFFIlEVFlZqVWrVuWqfgBFgN4BYKyMwsff//533X777Xr33Xd1wQUX6JprrtELL7yghQsXSpI2b96sEydOaN26dRoaGlJ9fb06Ojrk9XpzUjyA4kDvADCWyxhj8l3EWMlkUj6fL99llK0C++tg3Sdd4FiOEolE0VxLMdo7mrRSbteMfJdTdt7432vyXUJeXXTfC/kuIe9OmZM6ooOT6ht8twsAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACscue7ABQWl8uV7xIAFKGL7nsh3yWgiLDyAQAArMo4fLz99tu64447dN5556myslJXXHGFjh496uw3xqitrU3BYFAVFRVqampSX19fVosGUHzoHQBGZRQ+hoaGtHTpUs2YMUNPPfWUjh07ph/+8If67Gc/6xyzfft27dixQ+3t7eru7lYgEFBzc7OGh4ezXTuAIkHvADCWyxhjJnvw1q1b9cc//lHPPffchPuNMQoGgwqHw9qyZYskKZVKye/366GHHtKaNWs+9TWSyaR8Pt9kSwKQQ4lEQlVVVdN+Hpu9o0kr5XbNmHbNADJzypzUER2cVN/IaOXj0KFDqqur06233qq5c+dq8eLF2rNnj7O/v79f8XhcLS0tzjaPx6PGxkZ1dXVN+JypVErJZDJtACgt9A4AY2UUPt58803t2rVLoVBIhw8f1tq1a3XvvffqsccekyTF43FJkt/vT3uc3+939p0pGo3K5/M5o7q6eiq/B4ACRu8AMFZG4eP06dO68sorFYlEtHjxYq1Zs0bf/OY3tWvXrrTjzvy4pjHmrB/hbG1tVSKRcMbAwECGvwKAQkfvADBWRuFj3rx5uvTSS9O2XXLJJXrrrbckSYFAQJLGvVMZHBwc945mlMfjUVVVVdoAUFroHQDGyih8LF26VK+++mrattdee00LFy6UJNXU1CgQCKizs9PZPzIyolgspoaGhiyUC6AY0TsAjJXRHU7vu+8+NTQ0KBKJ6Ktf/apefPFF7d69W7t375b08ZJpOBxWJBJRKBRSKBRSJBJRZWWlVq1alZNfAEDho3cAGCuj8HHVVVfpiSeeUGtrqx588EHV1NRo586dWr16tXPM5s2bdeLECa1bt05DQ0Oqr69XR0eHvF5v1osHUBzoHQDGyug+HzZwnw+gcGTrPh82cJ8PIL9ydp8PAACA6SJ8AAAAqwgfAADAKsIHAACwKqNPu9hQYNe/AmWtmP49jtZ6Siel4ikbKBmndFLS5PpGwYUPvj4bKBzDw8NF8+mz0d7xvJ7McyVAeZtM3yi4j9qePn1a77zzjowxWrBggQYGBormo362JJNJVVdXMzdnYF7OLtO5McZoeHhYwWBQ55xTHGdn6R2fjH8fZ8fcTCyXfaPgVj7OOecczZ8/3/l6bL6z4eyYm4kxL2eXydwUy4rHKHrH5DAvZ8fcTCwXfaM43tIAAICSQfgAAABWFWz48Hg8euCBB+TxePJdSsFhbibGvJxdOc1NOf2umWBezo65mVgu56XgLjgFAAClrWBXPgAAQGkifAAAAKsIHwAAwCrCBwAAsIrwAQAArCrY8PHII4+opqZGs2bN0pIlS/Tcc8/luySrotGorrrqKnm9Xs2dO1c333yzXn311bRjjDFqa2tTMBhURUWFmpqa1NfXl6eK8yMajcrlcikcDjvbynle3n77bd1xxx0677zzVFlZqSuuuEJHjx519pf63NA36BuTRe/4r7z0DVOA9u/fb2bMmGH27Nljjh07ZjZu3Ghmz55t/va3v+W7NGtuvPFG8+ijj5o///nPpqenx6xYscIsWLDAvP/++84x27ZtM16v1zz++OOmt7fX3HbbbWbevHkmmUzmsXJ7XnzxRfP5z3/eLFq0yGzcuNHZXq7z8q9//cssXLjQ3H333eZPf/qT6e/vN7///e/NG2+84RxTynND36BvTBa947/y1TcKMnxcffXVZu3atWnbLr74YrN169Y8VZR/g4ODRpKJxWLGGGNOnz5tAoGA2bZtm3PMf/7zH+Pz+cxPfvKTfJVpzfDwsAmFQqazs9M0NjY6DaSc52XLli1m2bJlZ91f6nND3xiPvjEevSNdvvpGwZ12GRkZ0dGjR9XS0pK2vaWlRV1dXXmqKv8SiYQkac6cOZKk/v5+xePxtHnyeDxqbGwsi3lav369VqxYoRtuuCFteznPy6FDh1RXV6dbb71Vc+fO1eLFi7Vnzx5nfynPDX1jYvSN8egd6fLVNwoufLz77rv66KOP5Pf707b7/X7F4/E8VZVfxhht2rRJy5YtU21trSQ5c1GO87R//369/PLLikaj4/aV87y8+eab2rVrl0KhkA4fPqy1a9fq3nvv1WOPPSaptOeGvjEefWM8esd4+eob7qmXnFsulyvtZ2PMuG3lYsOGDXrllVf0/PPPj9tXbvM0MDCgjRs3qqOjQ7NmzTrrceU2L5J0+vRp1dXVKRKJSJIWL16svr4+7dq1S1//+ted40p5bkr5d8sUfSMdvWNi+eobBbfycf755+vcc88dl6gGBwfHJa9ycM899+jQoUP6wx/+oPnz5zvbA4GAJJXdPB09elSDg4NasmSJ3G633G63YrGYHn74Ybndbud3L7d5kaR58+bp0ksvTdt2ySWX6K233pJU2n9n6Bvp6Bvj0Tsmlq++UXDhY+bMmVqyZIk6OzvTtnd2dqqhoSFPVdlnjNGGDRt04MABPfPMM6qpqUnbX1NTo0AgkDZPIyMjisViJT1P119/vXp7e9XT0+OMuro6rV69Wj09PbrwwgvLcl4kaenSpeM+Vvnaa69p4cKFkkr77wx942P0jbOjd0wsb31jypeq5tDoR+Z+9rOfmWPHjplwOGxmz55t/vrXv+a7NGu+9a1vGZ/PZ44cOWKOHz/ujA8//NA5Ztu2bcbn85kDBw6Y3t5ec/vtt5f8x8ImMvaKdWPKd15efPFF43a7zfe//33z+uuvm1/+8pemsrLS/OIXv3COKeW5oW/QNzJF78hf3yjI8GGMMT/+8Y/NwoULzcyZM82VV17pfFSsXEiacDz66KPOMadPnzYPPPCACQQCxuPxmOuuu8709vbmr+g8ObOBlPO8/Pa3vzW1tbXG4/GYiy++2OzevTttf6nPDX2DvpEJesfH8tE3XMYYM/V1EwAAgMwU3DUfAACgtBE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYNX/ATxR1zQ5oT7TAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_image = cv2.imread('shapes_dataset/train_images/train/0.png')\n",
    "example_mask = cv2.imread('shapes_dataset/train_masks/train/0.png', 0) # read it as grayscale\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(example_image)\n",
    "ax[1].imshow(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 255], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(example_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading all to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *AlMOST* SAME AS NOTEBOOK 7\n",
    "# Diff 1: output layer Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "# Diff 2: loss='categorical_crossentropy'\n",
    "# Diff 3: multiclass_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, n_classes)\n",
    "\n",
    "# U-Net model\n",
    "# Author: Sreenivas Bhattiprolu\n",
    "# This code is coming from the videos at the beginning\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "def multiclass_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, n_classes): # changed\n",
    "# Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    # Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9) # changed\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1]) # changed\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:01:18.857714: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-12-06 22:01:18.857731: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-12-06 22:01:18.857737: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-12-06 22:01:18.857769: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-06 22:01:18.857784: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 64, 64, 16)           448       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64, 64, 16)           0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 16)           2320      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 16)           0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)           4640      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 32, 32, 32)           0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 32)           9248      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 16, 16, 64)           0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)           36928     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 128)            73856     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 8, 8, 128)            0         ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 128)            147584    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 128)            0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 256)            295168    ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 4, 4, 256)            0         ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 256)            590080    ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 8, 8, 128)            131200    ['conv2d_9[0][0]']            \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 8, 8, 256)            0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)            295040    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 8, 8, 128)            0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)            147584    ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 16, 16, 64)           32832     ['conv2d_11[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 16, 16, 128)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 16, 16, 64)           73792     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 16, 16, 64)           0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 32, 32, 32)           8224      ['conv2d_13[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 32, 32, 64)           0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 32)           18464     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 32, 32, 32)           0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 64, 64, 16)           2064      ['conv2d_15[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 64, 64, 32)           0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 16)           4624      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 64, 64, 16)           0         ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 64, 64, 3)            51        ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1941139 (7.40 MB)\n",
      "Trainable params: 1941139 (7.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_unet_model(64, 64, 3, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "X_train = []\n",
    "y_train = []\n",
    "for im_path in glob.glob('shapes_dataset/train_images/train/*.png'):\n",
    "    mask_path = im_path.replace('images', 'masks')\n",
    "    im = cv2.imread(im_path)\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    X_train.append(im)\n",
    "    y_train.append(mask)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "for im_path in glob.glob('shapes_dataset/val_images/val/*.png'):\n",
    "    mask_path = im_path.replace('images', 'masks')\n",
    "    im = cv2.imread(im_path)\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    X_val.append(im)\n",
    "    y_val.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 64, 64, 3), (500, 64, 64), (100, 64, 64, 3), (100, 64, 64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct mask format for multiclass UNet**\n",
    "\n",
    "One important point is, you need to convert the masks to categorical. Currently it is one channel with all the labels (0, 1, 2). But similar to multiclass classification, we should preprocess this into (1, 0, 0) (0, 1, 0) and (0, 0, 1). You can think of this as color channels, where instead of colors we have binary label masks in each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 64, 64, 3), (100, 64, 64, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_val = to_categorical(y_val, num_classes=3)\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e69c5160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo of the output format\n",
    "example_mask = y_train[0]\n",
    "rectangle_channel = example_mask[:, :, 1]\n",
    "triangle_channel = example_mask[:, :, 2]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(rectangle_channel)\n",
    "ax[1].imshow(triangle_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I did not normalize the input images. Normally you should. But because this is a simple dataset, it will still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:01:20.335001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 2.4955 - accuracy: 0.9235 - f1: 0.9242 - iou: 0.8701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:01:22.272941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 52ms/step - loss: 2.4955 - accuracy: 0.9235 - f1: 0.9242 - iou: 0.8701 - val_loss: 0.1479 - val_accuracy: 0.9708 - val_f1: 0.9708 - val_iou: 0.9503\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2964 - accuracy: 0.9628 - f1: 0.9631 - iou: 0.9361 - val_loss: 0.0718 - val_accuracy: 0.9784 - val_f1: 0.9788 - val_iou: 0.9664\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1618 - accuracy: 0.9708 - f1: 0.9716 - iou: 0.9525 - val_loss: 0.0485 - val_accuracy: 0.9807 - val_f1: 0.9817 - val_iou: 0.9740\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0956 - accuracy: 0.9775 - f1: 0.9784 - iou: 0.9657 - val_loss: 0.0316 - val_accuracy: 0.9917 - val_f1: 0.9871 - val_iou: 0.9827\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0587 - accuracy: 0.9848 - f1: 0.9842 - iou: 0.9763 - val_loss: 0.0262 - val_accuracy: 0.9936 - val_f1: 0.9892 - val_iou: 0.9860\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0391 - accuracy: 0.9899 - f1: 0.9886 - iou: 0.9836 - val_loss: 0.0177 - val_accuracy: 0.9958 - val_f1: 0.9933 - val_iou: 0.9911\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0275 - accuracy: 0.9934 - f1: 0.9927 - iou: 0.9891 - val_loss: 0.0125 - val_accuracy: 0.9975 - val_f1: 0.9964 - val_iou: 0.9948\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0213 - accuracy: 0.9956 - f1: 0.9953 - iou: 0.9927 - val_loss: 0.0064 - val_accuracy: 0.9989 - val_f1: 0.9986 - val_iou: 0.9977\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0148 - accuracy: 0.9972 - f1: 0.9970 - iou: 0.9952 - val_loss: 0.0049 - val_accuracy: 0.9991 - val_f1: 0.9990 - val_iou: 0.9983\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0130 - accuracy: 0.9977 - f1: 0.9976 - iou: 0.9961 - val_loss: 0.0046 - val_accuracy: 0.9992 - val_f1: 0.9990 - val_iou: 0.9984\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0120 - accuracy: 0.9979 - f1: 0.9978 - iou: 0.9963 - val_loss: 0.0034 - val_accuracy: 0.9993 - val_f1: 0.9992 - val_iou: 0.9987\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9984 - f1: 0.9984 - iou: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9994 - val_f1: 0.9993 - val_iou: 0.9989\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9986 - f1: 0.9985 - iou: 0.9974 - val_loss: 0.0029 - val_accuracy: 0.9994 - val_f1: 0.9993 - val_iou: 0.9989\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0096 - accuracy: 0.9983 - f1: 0.9983 - iou: 0.9971 - val_loss: 0.0034 - val_accuracy: 0.9994 - val_f1: 0.9993 - val_iou: 0.9988\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0070 - accuracy: 0.9988 - f1: 0.9987 - iou: 0.9979 - val_loss: 0.0022 - val_accuracy: 0.9995 - val_f1: 0.9995 - val_iou: 0.9992\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9988 - f1: 0.9988 - iou: 0.9980 - val_loss: 0.0023 - val_accuracy: 0.9995 - val_f1: 0.9995 - val_iou: 0.9991\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0058 - accuracy: 0.9989 - f1: 0.9989 - iou: 0.9981 - val_loss: 0.0019 - val_accuracy: 0.9996 - val_f1: 0.9995 - val_iou: 0.9992\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0052 - accuracy: 0.9991 - f1: 0.9991 - iou: 0.9984 - val_loss: 0.0022 - val_accuracy: 0.9995 - val_f1: 0.9994 - val_iou: 0.9990\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9991 - f1: 0.9991 - iou: 0.9985 - val_loss: 0.0022 - val_accuracy: 0.9995 - val_f1: 0.9994 - val_iou: 0.9991\n"
     ]
    }
   ],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "cb = EarlyStopping(monitor='val_loss',\n",
    "                   patience=2,\n",
    "                   restore_best_weights='True',\n",
    "                   mode='min')\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=16,\n",
    "                    verbose=1,\n",
    "                    epochs=100, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at example predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:01:37.929460: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "predicted_masks = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64, 64, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output has channels where each channel is a class\n",
    "predicted_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e5407f10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We need to do argmax to get predicted labels\n",
    "i = 2\n",
    "prediction = np.argmax(predicted_masks[i], axis=2)\n",
    "ground_truth = np.argmax(y_val[i], axis=2)\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(X_val[i])\n",
    "ax[1].imshow(ground_truth)\n",
    "ax[2].imshow(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Back to the original shape\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Flow from directory\n",
    "\n",
    "Now this part is also very similar to Notebook 7. The only issue is we need to add the `to_categorical` step.\n",
    "\n",
    "`ImageDataGenerator()` has a parameter called `preprocessing_function` but the documentation says\n",
    "\n",
    ">The function should take one argument: one image (Numpy tensor with rank 3), and should output a Numpy tensor with the same shape.\n",
    "\n",
    "Which means it won't allow `to_categorical` because it changes the shape of the array. So I used a custom generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def custom_generator(dataset_type, batch_size, target_size):\n",
    "    image_datagen = ImageDataGenerator()\n",
    "    mask_datagen = ImageDataGenerator()\n",
    "\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        f'shapes_dataset/{dataset_type}_images',\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        target_size=target_size,\n",
    "        seed=42)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        f'shapes_dataset/{dataset_type}_masks',\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        target_size=target_size,\n",
    "        color_mode='grayscale',\n",
    "        seed=42)\n",
    "    \n",
    "    # Here I can add the to_categorical part\n",
    "    while True:\n",
    "        X = image_generator.next()\n",
    "        Y = mask_generator.next()\n",
    "        Y = to_categorical(Y, num_classes=3)  # Convert masks to categorical\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = custom_generator('train', batch_size=32, target_size=(64, 64))\n",
    "val_gen = custom_generator('val', batch_size=32, target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 64, 64, 16)           448       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 64, 64, 16)           0         ['conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 32, 32, 16)           0         ['conv2d_20[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 32, 32, 32)           4640      ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 32, 32, 32)           0         ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_22[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 64)           18496     ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 16, 16, 64)           0         ['conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_24[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 8, 8, 128)            73856     ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 8, 8, 128)            0         ['conv2d_25[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 8, 8, 128)            147584    ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 4, 4, 128)            0         ['conv2d_26[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 4, 4, 256)            295168    ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 4, 4, 256)            0         ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 4, 4, 256)            590080    ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 8, 8, 128)            131200    ['conv2d_28[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 8, 8, 256)            0         ['conv2d_transpose_4[0][0]',  \n",
      " )                                                                   'conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 8, 8, 128)            295040    ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 8, 8, 128)            0         ['conv2d_29[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 128)            147584    ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2D  (None, 16, 16, 64)           32832     ['conv2d_30[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 16, 16, 128)          0         ['conv2d_transpose_5[0][0]',  \n",
      " )                                                                   'conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 64)           73792     ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 16, 16, 64)           0         ['conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_15[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 32, 32, 32)           8224      ['conv2d_32[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 32, 32, 64)           0         ['conv2d_transpose_6[0][0]',  \n",
      " )                                                                   'conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 32, 32, 32)           18464     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 32, 32, 32)           0         ['conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2D  (None, 64, 64, 16)           2064      ['conv2d_34[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 64, 64, 32)           0         ['conv2d_transpose_7[0][0]',  \n",
      " )                                                                   'conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 64, 64, 16)           4624      ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 64, 64, 16)           0         ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 3)            51        ['conv2d_36[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1941139 (7.40 MB)\n",
      "Trainable params: 1941139 (7.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_unet_model(64, 64, 3, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am cheating here a little\n",
    "# Generators have an attribute to get dataset size\n",
    "# but since I wrote a custom one, I did not implement such attributes\n",
    "# I am simply checking the size from X_train/X_val, but you can check it without loading images to memory\n",
    "num_of_train_images = X_train.shape[0]\n",
    "num_of_val_images = X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:01:39.282129: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/15 [===========================>..] - ETA: 0s - loss: 11.1209 - accuracy: 0.8011 - f1: 0.7903 - iou: 0.7095Found 100 images belonging to 1 classes.\n",
      "Found 100 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:01:40.870228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 82ms/step - loss: 10.5842 - accuracy: 0.8108 - f1: 0.8007 - iou: 0.7221 - val_loss: 1.4630 - val_accuracy: 0.9575 - val_f1: 0.9521 - val_iou: 0.9049\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 2.2041 - accuracy: 0.9527 - f1: 0.9520 - iou: 0.9095 - val_loss: 0.7040 - val_accuracy: 0.9712 - val_f1: 0.9692 - val_iou: 0.9357\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 1.2266 - accuracy: 0.9618 - f1: 0.9615 - iou: 0.9270 - val_loss: 0.3947 - val_accuracy: 0.9779 - val_f1: 0.9770 - val_iou: 0.9527\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.7632 - accuracy: 0.9664 - f1: 0.9661 - iou: 0.9363 - val_loss: 0.1647 - val_accuracy: 0.9847 - val_f1: 0.9843 - val_iou: 0.9689\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.4429 - accuracy: 0.9745 - f1: 0.9745 - iou: 0.9528 - val_loss: 0.0556 - val_accuracy: 0.9933 - val_f1: 0.9932 - val_iou: 0.9872\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2592 - accuracy: 0.9825 - f1: 0.9824 - iou: 0.9676 - val_loss: 0.0339 - val_accuracy: 0.9971 - val_f1: 0.9973 - val_iou: 0.9944\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1550 - accuracy: 0.9886 - f1: 0.9887 - iou: 0.9793 - val_loss: 0.0597 - val_accuracy: 0.9962 - val_f1: 0.9965 - val_iou: 0.9932\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1104 - accuracy: 0.9916 - f1: 0.9916 - iou: 0.9847 - val_loss: 0.0212 - val_accuracy: 0.9983 - val_f1: 0.9981 - val_iou: 0.9964\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0811 - accuracy: 0.9938 - f1: 0.9938 - iou: 0.9887 - val_loss: 0.0229 - val_accuracy: 0.9986 - val_f1: 0.9986 - val_iou: 0.9971\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0684 - accuracy: 0.9949 - f1: 0.9949 - iou: 0.9907 - val_loss: 0.0282 - val_accuracy: 0.9984 - val_f1: 0.9988 - val_iou: 0.9976\n"
     ]
    }
   ],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "cb = EarlyStopping(monitor='val_loss',\n",
    "                   patience=2,\n",
    "                   restore_best_weights='True',\n",
    "                   mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch = num_of_train_images//32,\n",
    "    epochs=100,\n",
    "    validation_data = val_gen,\n",
    "    validation_steps = num_of_val_images//32,\n",
    "    callbacks=[cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:01:46.307467: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 64, 64, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_masks = model.predict(X_val)\n",
    "predicted_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1719c8d00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "prediction = np.argmax(predicted_masks[i], axis=2)\n",
    "ground_truth = np.argmax(y_val[i], axis=2)\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(X_val[i])\n",
    "ax[1].imshow(ground_truth)\n",
    "ax[2].imshow(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y2b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
