{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome!üëã\n",
    "\n",
    "In this introductory Jupyter notebook, we delve into the fascinating world of image processing using OpenCV and scikit-image. We will start with the fundamentals of working with digital images (sections 1-6). Then you will learn about important image processing operations (7-10). This introduction will form the foundation for all computer vision tasks you will do later in this block.\n",
    "\n",
    "1. Loading, Displaying and Saving an Image\n",
    "2. What is a digital image?\n",
    "3. Color models\n",
    "4. Drawing\n",
    "5. scikit-image\n",
    "6. Sample images\n",
    "7. Image transformations\n",
    "8. Histograms\n",
    "9. Binary Image\n",
    "10. Combining Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading, Displaying and Saving an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process images we need to first read them. Let's see how you can read an image with OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Image height: {im.shape[0]} px')\n",
    "print(f'Image width: {im.shape[1]} px')\n",
    "print(f'Number of channels: {im.shape[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.1**\n",
    "\n",
    "Check the _type_ and _data type_ of `im`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`im` is a numpy array (`numpy.ndarray`) containing 8 bit unsigned integers (`uint8`). When working with OpenCV, make sure that your images are numpy arrays with the data type `uint8`. OpenCV functions can work with other data types but `uint8` is the most common one.\n",
    "\n",
    "Let's display the image we just loaded using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks weird. A penny is copper coated zinc and copper has a brownish-orange color. Something is wrong. As competent data scientists, what should we do? We read the documentation üòÅ\n",
    "\n",
    "`cv2.imread()` [documentation](https://docs.opencv.org/3.4/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56) says:\n",
    "\n",
    "> In the case of color images, the decoded images will have the channels stored in B G R order.\n",
    "\n",
    "`plt.imshow()` [documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) says:\n",
    "\n",
    "> (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
    "\n",
    "This means OpenCV reads color channels in BGR order whereas matplotlib uses RGB ordering. We need to convert BGR to RGB before using `plt.imshow()`. We can do this with numpy as follows:\n",
    "\n",
    "```python\n",
    "im = im[:, :, [2, 1, 0]]\n",
    "```\n",
    "\n",
    "Converting colors from one space to another is so common that OpenCV has a method for that called `cvtColor()`. Let's see how this works for this conversion BGR -> RGB:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this looks better! OpenCV has its own function to display images `cv2.imshow()`. But instead of displaying the image inside the notebook, it opens an external window. Check its documentation [here](https://docs.opencv.org/4.x/d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563). Therefore we will use matplotlib to display images.\n",
    "\n",
    "Let's look at another conversion: RGB -> grayscale. In image processing, grayscale is commonly used because many processing techniques do not need color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, channel axis just disappeared. Notice that (317, 612, 1) could also be a grayscale image shape. You could also read an image as grayscale as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0) # 0 flag\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm color blind but even I can see some color here, it is not grayscale. So what is going on? By reading the documentation, we learn that `plt.imshow()` method has a `cmap` parameter and it has a default color map called `viridis`.\n",
    "\n",
    ">cmap: Colormap, default: 'viridis'\\\n",
    "The Colormap instance or registered colormap name used to map scalar data to colors.\\\n",
    "This parameter is ignored if X is RGB(A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use the color map suitable for grayscale images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take a look at all the colormaps in matplotlib from [here](https://matplotlib.org/stable/users/explain/colors/colormaps.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final operation I would like to show you before finishing this section is to how to save an image. We can save the grayscale image as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('images/im_gray.jpg', im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.2**\n",
    "\n",
    "- Read any RGB image from your computer.\n",
    "- Display it.\n",
    "- Convert it to grayscale.\n",
    "- Display it again.\n",
    "- Save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is a digital image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image is a visual representation or depiction of objects, scenes, or information, typically composed of patterns of varying light and color, that can be either analog or digital in nature. In computer vision, we work with digital images.\n",
    "\n",
    "When we zoom into a digital image, we see square regions with a single color. These are the building blocks an digital image - pixels. The word pixel is a combination of pix (from \"pictures\", shortened to \"pics\") and el (for \"element\").\n",
    "\n",
    "Let's zoom into the eagle on one of the coins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0)\n",
    "zoomed_im = im[170:230, 70:130]\n",
    "plt.imshow(zoomed_im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom even more to the head of the eagle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomed_im = im[190:210, 88:108]\n",
    "plt.imshow(zoomed_im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each square is a pixel. In a grayscale image, each pixel has a value between 0 (black) and 255 (white). The values in between 0 and 255 are varying shades of gray, where values closer to 0 are darker and values closer to 255 are lighter. Let's display pixel values on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.imshow(zoomed_im, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "for i in range(zoomed_im.shape[0]):\n",
    "    for j in range(zoomed_im.shape[1]):\n",
    "        ax.text(j, i, str(zoomed_im[i, j]), color='r', ha='center', va='center', size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know a binary digit (bit) has two possible values 0 or 1. If you have 2 bits, you can represent 4 numbers: 00, 01, 10, 11. With n bits you can represent $2^n$ numbers. With 8 bits, you can represent $2^8=256$ numbers which means we can represent a pixel value with 8 bits. The number of bits used to define a pixel is called _bit depth_. You can encounter 16-bit or 24-bit images in some applications. The greater the bit depth, the greater the number of tones (grayscale or color) that can be represented.\n",
    "\n",
    "This is why the image data type is `uint8`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**\n",
    "\n",
    "You need to keep in mind the following when using `plt.imshow()` on grayscale images.\n",
    "\n",
    "Let's create and display a very small image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_px_image = np.array([[100, 110],\n",
    "                          [130, 150]], dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(four_px_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what? ü§Øü§®üòµ How can a pixel value of 100 be black and 150 be white? Let's check the documentation of `plt.imshow()`. It turns out, there are parameters called `vmin` and `vmax`:\n",
    "\n",
    ">When using scalar data and no explicit norm, vmin and vmax define the data range that the colormap covers. _By default, the colormap covers the complete value range of the supplied data_. This parameter is ignored if X is RGB(A).\n",
    "\n",
    "It seems like colormap by default finds the minimum and maximum pixel values and sets them as black and white respectively. And this does not happen for RGB images, only for grayscale. This means we need to supply vmin=0 and vmax=255 to ensure true shades of gray.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(four_px_image, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this looks better üôÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.3**\n",
    "\n",
    "Calculate the average and standard deviation of pixel values in the grayscale image `im`.\n",
    "\n",
    "Expected answer\n",
    "- Average = 212.78\n",
    "- Standard deviation = 57.61\n",
    "\n",
    "What does average pixel intensity being low/high would mean? What does standard deviation of pixel intensity being low/high would mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Color models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common way to represent color pixels is the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model). Each color pixel is represented by 3 channels, Red, Green and Blue. Each channel has a value between 0 and 255. Combining these 3 channels gives us a color in the RGB color space.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1024px-Venn_diagram_rgb.svg.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some example colors, represented as RGB tuples:\n",
    "\n",
    "|RGB|Color|\n",
    "|--|--|\n",
    "|(0, 0, 0)| Black|\n",
    "|(255, 255, 255)| White|\n",
    "|(255, 0, 0)| Red|\n",
    "|(0, 255, 0)| Green|\n",
    "|(0, 0, 255)| Blue|\n",
    "|(128, 128, 0)| Olive|\n",
    "|(255, 255, 0)| Yellow|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create an RGB image (64, 64, 3) where every pixel has the color olive.\n",
    "r = np.ones((64, 64), dtype = 'uint8') * 128\n",
    "g = np.ones((64, 64), dtype = 'uint8') * 128\n",
    "b = np.zeros((64, 64), dtype = 'uint8')\n",
    "\n",
    "im_olive = np.stack((r, g, b), axis=2)\n",
    "\n",
    "plt.imshow(im_olive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other color spaces you will encounter are CMYK (Cyan, Magenta, Yellow, Black) and HSV (Hue, Saturation, Value). It is not easy to change the saturation of an image in RGB representation whereas it is very easy when you use the HSV representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.4**\n",
    "\n",
    "Create the (64, 64, 3) image below. Colored regions are (32, 32, 3) squares.\n",
    "\n",
    "<img src='images/rgb_exercise.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resolution\n",
    "\n",
    "What is resolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape[0] * im.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this image contains 194,004 pixels.\n",
    "\n",
    "**Image resolution** is the level of detail an image holds, it is described in many different ways. One way is to count the number of pixels in an image. A 2 megapixel camera captures 2 million pixels in a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another metric to measure resolution is pixel per inch (PPI). It is the number of pixels in one inch. But to calculate PPI we need to know an actual distance on the image. Luckily, the image contains US coins, and their sizes are standardized. Let's first find the diameter of the penny in pixels. Let's do this manually for now, later we will see the image processing techniques to automate measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find a line that cuts the penny in half\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.plot([450, 600], [88, 88])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the cross section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(im[88, 450:600])\n",
    "plt.ylabel('Pixel value')\n",
    "plt.xlabel('Pixel location on the blue line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the pixel values of the pixels on the blue line\n",
    "blue_line = im[88, 450:600]\n",
    "blue_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the following assumption: `blue_line` pixels whose values are not 255 belong to the coin. In that case, the number of non-255 pixels will give us the diameter of one cent in terms of pixels.\n",
    "\n",
    "**Exercise 1.5**\n",
    "\n",
    "Find the diameter of the coin by counting the non-255 pixels on the `blue_line`. Expected result is 111 px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "d_cent_px = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you solve the exercise above you can remove this cell\n",
    "if d_cent_px is None:\n",
    "    d_cent_px = 111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diameter of a cent is 0.750 inches. Specs here:\n",
    "\n",
    "https://www.usmint.gov/learn/coin-and-medal-programs/coin-specifications\n",
    "\n",
    "**Exercise 1.6**\n",
    "\n",
    "Calculate the PPI. Expected answer is 148 ppi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "d_cent_inch = 0.750 # inch\n",
    "ppi = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover measuring objects in detail later. Not every image has standard objects that we can use readily. This is why we have scale bars, especially in microscopy and maps. Here is a scanning electron microscope (SEM) image with 100 ¬µm scale bar.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Pos.tif/lossy-page1-1280px-Pos.tif.jpg' width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Image Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In geometry, a Cartesian coordinate system in a plane is a coordinate system that specifies each point uniquely by a pair of real numbers called coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, called coordinate lines, coordinate axes or just axes (plural of axis) of the system. The point where they meet is called the origin and has (0, 0) as coordinates. You can see how 4 example points are represented by coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .white {\n",
    "        background-color: #FFFFFF;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div class=\"white\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Cartesian-coordinate-system.svg/1024px-Cartesian-coordinate-system.svg.png\" width=300/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Cartesian coordinate system to represent pixel positions. In image processing, however, by convention y-axis is oriented downwards while x-axis stays the same. This is why, when we display images with `plt.imshow()` x-axis values increase from left to right, whereas y-axis values increase from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this convention, top left pixel is the origin (0, 0). Let's plot 3 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')\n",
    "plt.scatter(x=0, y=0, c='red', s=100) # (0,0)\n",
    "plt.scatter(x=0, y=80, c='blue', s=100) # (0, 80)\n",
    "plt.scatter(x=380, y=80, c='green', s=100) # (380, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.7**\n",
    "\n",
    "What is the center (x, y) of the coin on the bottom row, second from the left (one dime)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "x = None\n",
    "y = None\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.scatter(x, y, c='green', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.8**\n",
    "\n",
    "What is the value of the pixel (380, 80)? The expected answer is 186. Think about the relationship between x, y and row, column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.9**\n",
    "\n",
    "What is the Euclidean distance between the points (0, 0) and (380, 80)? The expected answer is 388.33 px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.10**\n",
    "\n",
    "Display the coin on the top left by slicing the `im`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing lines, boxes, circles on images is indispensible in CV. After all, object detection is drawing bounding boxes around objects üñç\n",
    "\n",
    "<img src='https://i.imgur.com/wdrAWUI.png' width=800\\>\n",
    "\n",
    "[J. Redmon et al, _You only look once: Unified, real-time object detection_, 2016](https://arxiv.org/abs/1506.02640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by drawing a line:\n",
    "\n",
    "`cv2.line(image, start_point, end_point, color, thickness)`\n",
    "\n",
    "Remember, default color space in OpenCV is... BGR which means if you want to draw a red line you pass (0, 0, 255) as the color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image diagonal\n",
    "im = cv2.imread('images/coins.jpeg')\n",
    "im_with_line = cv2.line(im, (0, 0), (im.shape[1], im.shape[0]), (0, 0, 255), 5)\n",
    "im_with_line = cv2.cvtColor(im_with_line, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im_with_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing your first bounding box ü•π\n",
    "\n",
    "`cv2.rectangle(image, start_point, end_point, color, thickness)`\n",
    "\n",
    "- start_point: coordinates of the top left corner\n",
    "- end_point: coordinates of the bottom right corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box\n",
    "im = cv2.imread('images/coins.jpeg')\n",
    "im_with_rectangle = cv2.rectangle(im, (190, 185), (289, 283), (0, 0, 255), 2)\n",
    "im_with_rectangle = cv2.cvtColor(im_with_rectangle, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im_with_rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to fill the object set thickness to -1\n",
    "im = cv2.imread('images/coins.jpeg')\n",
    "im_with_rectangle = cv2.rectangle(im, (190, 185), (289, 283), (0, 0, 255), -1)\n",
    "im_with_rectangle = cv2.cvtColor(im_with_rectangle, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im_with_rectangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.11**\n",
    "\n",
    "Draw a bounding box around another coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.12**\n",
    "\n",
    "Given the following:\n",
    "\n",
    "`cv2.circle(image, center_coordinates, radius, color, thickness)`\n",
    "\n",
    "draw a circle around any coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have covered image basics using `OpenCV`. There is another image processing library called `scikit-image`. You need to learn both because they have advantages over each other. Since you already know image basics, we will cover the syntax of `scikit-image` in comparison with `OpenCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "im = skimage.io.imread('images/coins.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(im), im.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skimage works with uint8 numpy arrays too. But the default color space is RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image as gray\n",
    "im = skimage.io.imread('images/coins.jpeg', as_gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but when you read it as gray this happens\n",
    "print(f'Pixel data type is {im.dtype} and values are between {np.min(im)} and {np.max(im)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can convert this to 0-255 integers as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im * 255\n",
    "im = im.astype('uint8')\n",
    "print(f'Pixel data type is {im.dtype} and values are between {np.min(im)} and {np.max(im)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing with `scikit-image` is also little different than `OpenCV`. Instead of (x, y) it uses (row, column) for the coordinates which means (y, x).\n",
    "\n",
    "```\n",
    "rr, cc = skimage.draw.rectangle_perimeter(\n",
    "    start=(top_left_y, top_left_x),\n",
    "    end=(bottom_right_y, bottom_right_x),\n",
    "    shape=image.shape)\n",
    "```\n",
    "\n",
    "another difference is `OpenCV` drawing methods returned the output image. `scikit-image` returns the coordinates. Therefore, we need to set the pixels defined by those coordinates into the color we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr, cc = skimage.draw.rectangle_perimeter(start=(185, 190), end=(283, 289), shape=im.shape)\n",
    "im[rr, cc] = 0  # Set rectangle pixels to black\n",
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can find all the shapes you can draw here:\n",
    "\n",
    "https://scikit-image.org/docs/stable/api/skimage.draw.html#module-skimage.draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.13**\n",
    "\n",
    "Check the available modules and the methods in scikit-image:\n",
    "\n",
    "https://scikit-image.org/docs/stable/api/api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both OpenCV and scikit-image has sample images that are used to demonstrate CV operations.\n",
    "\n",
    "OpenCV samples are here: https://github.com/opencv/opencv/tree/master/samples/data\n",
    "\n",
    "scikit-image sample images are easier to access: https://scikit-image.org/docs/stable/api/skimage.data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_im = skimage.data.astronaut()\n",
    "plt.imshow(sample_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skimage.data.rocket())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skimage.data.cell(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.14**\n",
    "\n",
    "- Go to here: https://scikit-image.org/docs/stable/api/skimage.data.html#\n",
    "- Read how `skimage.data.binary_blobs()` function works\n",
    "- Generate binary blobs using `skimage.data.binary_blobs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Image transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear algebra, the transpose of a matrix switches rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2],\n",
    "                [3, 4]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen images are matrices. What would happen if we transpose an image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_im = im.T\n",
    "transposed_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(transposed_im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is rotated 90 degrees counter clock wise. What if we would like to rotate an image 10 degrees, shift an image, obtain the mirror image, or rescale an image? All of these can be defined as matrix operations similar to the transpose operation.\n",
    "\n",
    "Read more here:\n",
    "- https://en.wikipedia.org/wiki/Transformation_matrix\n",
    "- https://en.wikipedia.org/wiki/Translation_(geometry)\n",
    "- https://en.wikipedia.org/wiki/Affine_transformation\n",
    "- https://en.wikipedia.org/wiki/Homography\n",
    "\n",
    "These transformation are already implemented in `OpenCV` and `scikit-image`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how you can rotate an image with `OpenCV`. First step is to calculate the transformation matrix and the second step is to apply this transformation matrix to the image:\n",
    "\n",
    "```\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "```\n",
    "- center: center of rotation (x, y)\n",
    "- angle: rotation angle in degrees (counter-clockwise)\n",
    "- scale: scale factor\n",
    "\n",
    "The `cv2.warpAffine()` function in OpenCV is used to apply an affine transformation to an image, which can include operations like translation, rotation, scaling, and shearing. Here's an explanation of its main parameters:\n",
    "```\n",
    "rotated_image = cv2.warpAffine(src, M, dsize)\n",
    "```\n",
    "- src: image to be transformed\n",
    "- M: 2x3 transformation matrix\n",
    "- dsize: size of the output (width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = im.shape[0]\n",
    "w = im.shape[1]\n",
    "\n",
    "center = (w/2, h/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 10\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "rotated_image = cv2.warpAffine(im, rotation_matrix, (w, h))\n",
    "plt.imshow(rotated_image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and with skimage\n",
    "from skimage.transform import rotate\n",
    "rotated_image = rotate(im, angle)\n",
    "plt.imshow(rotated_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that when we rotated the image, some parts of the image fell beyond the image borders. We can resize or pad the original image to prevent that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_image = rotate(im, angle, resize=True)\n",
    "plt.imshow(rotated_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.15**\n",
    "\n",
    "Resize the coins image using `OpenCV` and `scikit-image` to size (317, 317)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image histograms show the distribution of pixel intensities (i.e. values) in an image. In simpler terms, they tell you how many pixels have each possible brightness level. Bins in image histograms represent intervals for pixel values. In a histogram with 256 bins, each bin corresponds to a single pixel value. For 32 bins, each bin corresponds to 8 pixel values next to each other.\n",
    "\n",
    "You can compute histograms using numpy, OpenCV etc. Let's use `plt.hist()` to compute and plot the histogram of the coins image. It expects a 1-D array, therefore `im` needs to be reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(im.reshape(-1,), bins=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram we can see that most of the pixels are white (background) and there are some pixels that peak around 175 which must belong to the coins. We can access each bin size and value from `n` and `bins`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n # number of pixels in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins # bin edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {n[0]:.0f} pixels that has a value between {bins[0]:.0f}-{bins[1]:.0f}')\n",
    "print(f'There are {n[-1]:.0f} pixels that has a value between {bins[-2]:.0f}-{bins[-1]:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.16**\n",
    "\n",
    "Plot the histogram of the cell image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cell = skimage.data.cell()\n",
    "plt.imshow(im_cell, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the histogram, i.e. how many peaks do you see? which peak(s) represents the cell and which peak(s) represents the background?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Binary Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary image is a digital image composed of only two distinct pixel values, typically representing objects as foreground and background regions. Binary images are very common in image processing and some image processing methods only work on binary images. Let's see an example using our coins image.\n",
    "\n",
    "We will plot the same histogram but this time with a threshold of 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(im.reshape(-1,), bins=32)\n",
    "plt.axvline(x=230, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what if we set all pixel values above a threshold of 230 to `True` and rest to `False`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_im = im > 230\n",
    "plt.imshow(binary_im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a binary image. In other words, the pixels values have two possible values, in this case True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(binary_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the values does not matter we can have binary images with 0 or 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_im = binary_im * 1\n",
    "binary_im = binary_im.astype('uint8')\n",
    "np.unique(binary_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 0 or 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_im = binary_im * 255\n",
    "np.unique(binary_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is important is a binary image pixel can have only two values. Let's zoom into a coin edge and see what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(im[70:100, 20:50], cmap='gray', vmin=0, vmax=255)\n",
    "ax[0].set_title('Raw image')\n",
    "ax[1].imshow(binary_im[70:100, 20:50], cmap='gray', vmin=0, vmax=255)\n",
    "ax[1].set_title('Binary image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since most of the background pixel values are above 230, they are set to 255 in the binary image. And since most of the coin pixel values are below 230, they are set to 0 in the binary image.\n",
    "\n",
    "What we just did is called thresholding which can help use separate background and the foreground. We will cover thresholding in the next notebook in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.17**\n",
    "\n",
    "Considering the image and the histogram from Exercise 1.16 select an appropriate threshold to obtain the following binary image:\n",
    "\n",
    "<img src='images/cell_exercise.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cell = skimage.data.cell()\n",
    "plt.imshow(im_cell, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Combining Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with images, there will be applications which require combining images. This can be in the form of adding/subtracting images from each other (e.g. watermarks) or using one image as a mask on the other image to focus on a region. We can use _image arithmetic_ and _bitwise operations_ to combine images.\n",
    "\n",
    "Let's start with a simple example: what happens if we add 100 to all pixels values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0)\n",
    "im = im + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what kind of sorcery is this? Let's consider the white background pixels (255). In normal arithmetic 255 + 100 = 355. But pixel values are between 0 - 255, and 355 is not a valid pixel intensity. NumPy is doing modular arithmetic to handle values outside of 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mod(355, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the top left corner of the image\n",
    "im[0:10, 0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same with OpenCV and see if we get the same result (hint: we won't ü•≤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0)\n",
    "plt.imshow(im, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 100 to all pixels with OpenCV\n",
    "im = cv2.add(im, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the behaviour is totally different. The image looks washed out and brighter. OpenCV is clipping values instead of using the modular arithmetic. Let's look closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = np.array([[255, 200],\n",
    "                          [0, 150]], dtype='uint8')\n",
    "example_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers higher than 255 are clipped to 255\n",
    "cv2.add(example_image, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the bitwise operations AND, OR, XOR, NOT. To do that let's first create two binary images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rectangle = np.zeros((300, 300), dtype = \"uint8\")\n",
    "im_rectangle = cv2.rectangle(im_rectangle, (25, 25), (275, 275), 255, -1)\n",
    "\n",
    "im_circle = np.zeros((300, 300), dtype = \"uint8\")\n",
    "im_circle = cv2.circle(im_circle, (150, 150), 150, 255, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(im_rectangle, cmap='gray')\n",
    "ax[1].imshow(im_circle, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's combine these images with bitwise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(cv2.bitwise_and(im_rectangle, im_circle), cmap='gray') # AND\n",
    "ax[0].set_title('AND')\n",
    "ax[1].imshow(cv2.bitwise_or(im_rectangle, im_circle), cmap='gray') # OR\n",
    "ax[1].set_title('OR')\n",
    "ax[2].imshow(cv2.bitwise_xor(im_rectangle, im_circle), cmap='gray') # XOR\n",
    "ax[2].set_title('XOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these 3 outputs in detail to make sure you understand how AND OR and XOR operations work.\n",
    "\n",
    "We can also invert pixel values using NOT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(cv2.bitwise_not(im_circle), cmap='gray')\n",
    "ax[1].imshow(cv2.bitwise_not(im_rectangle), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0)\n",
    "plt.imshow(cv2.bitwise_not(im), cmap='gray', vmin=0, vmax=255) # NOT coins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of the key operations we can do with bitwise operations is called masking.\n",
    "\n",
    "Masking in image processing involves isolating a specific region or area of interest within an image while ignoring the rest. A mask, typically a binary image, is used to define the region to be preserved, with white pixels representing the region of interest and black pixels representing areas to be masked or ignored. This technique is commonly employed for segmenting objects in images, enabling selective processing and analysis of specific image regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/coins.jpeg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mask\n",
    "mask = np.zeros_like(im)\n",
    "mask = cv2.circle(mask, (99, 86), 67, 255, -1)\n",
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking the image\n",
    "masked_image = cv2.bitwise_and(im, mask)\n",
    "plt.imshow(masked_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can do masking with numpy as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask with 0s and 1s\n",
    "mask = mask/255\n",
    "mask = mask.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply that with the image\n",
    "plt.imshow(im * mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.18**\n",
    "\n",
    "Apply the mask you obtained in Exercise 1.17 to the cell image and extract the cell. Expected output:\n",
    "\n",
    "<img src='images/cell_mask_exercise.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cell = skimage.data.cell()\n",
    "plt.imshow(im_cell, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
